from domain.ai.schema import AIInput
from prompts import *
from data_converter import return_to_dict
from chatbot import chat_with_llm
from logger import print_log




async def process_check_meal(text: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì‹ì‚¬ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        text (str): ì‚¬ìš©ìì˜ ì…ë ¥ í…ìŠ¤íŠ¸

    Returns:
        str: AI ëª¨ë¸ì˜ ì‘ë‹µ í…ìŠ¤íŠ¸

    Raises:
        ValueError: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš°
    """
    print_log(f"ğŸ’¡ [AIëª¨ë¸] ë°›ì€ í…ìŠ¤íŠ¸: {text}")
    try:
        # ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        input_data = {"role": "user", "content": text}
        datasets = [input_data]
        
        # ì‹ì‚¬ í™•ì¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        response = chat_with_llm(datasets, custom_prompt=MEAL_CHECK_PROMPT)
        print_log(f"ğŸ—£ï¸ ëª¨ë¸ ì‘ë‹µ: {response}")
        return response
    except Exception as e:
        print_log(f"âŒ ì‹ì‚¬ í™•ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "error")
        raise ValueError(f"ì‹ì‚¬ í™•ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

async def process_induce_medicine(text: str) -> str:
    """
    ì‚¬ìš©ìì—ê²Œ ì•½ ë³µìš©ì„ ìœ ë„í•˜ëŠ” ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        text (str): ì‚¬ìš©ìì˜ ì…ë ¥ í…ìŠ¤íŠ¸

    Returns:
        str: AI ëª¨ë¸ì˜ ì‘ë‹µ í…ìŠ¤íŠ¸

    Raises:
        ValueError: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš°
    """
    print_log(f"ğŸ’¡ [AIëª¨ë¸] ë°›ì€ í…ìŠ¤íŠ¸: {text}")
    try:
        input_data = {"role": "user", "content": text}
        datasets = [input_data]
        
        # ì•½ ë³µìš© ìœ ë„ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        response = chat_with_llm(datasets, custom_prompt=MEDICINE_INDUCTION_PROMPT)
        print_log(f"ğŸ—£ï¸ ëª¨ë¸ ì‘ë‹µ: {response}")
        return response
    except Exception as e:
        print_log(f"âŒ ì•½ ë³µìš© ìœ ë„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "error")
        raise ValueError(f"ì•½ ë³µìš© ìœ ë„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

async def process_notify_medicine() -> str:
    """
    ì‚¬ìš©ìì—ê²Œ ì•½ ë³µìš© ì‹œê°„ì„ì„ ì•Œë¦¬ëŠ” ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

    Returns:
        str: AI ëª¨ë¸ì˜ ì‘ë‹µ í…ìŠ¤íŠ¸

    Raises:
        ValueError: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš°
    """
    print_log("ğŸ’¡ [AIëª¨ë¸] ì•½ ë³µìš© ì•Œë¦¼ ìš”ì²­")
    try:
        # ë¹ˆ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¡œ ì‹œì‘
        datasets = []
        response = chat_with_llm(datasets, custom_prompt=MEDICINE_NOTIFICATION_PROMPT)
        print_log(f"âœ… [AIëª¨ë¸] ì•½ ë³µìš© ì•Œë¦¼ ì‘ë‹µ: {response}")
        return response
    except Exception as e:
        print_log(f"âŒ ì•½ ë³µìš© ì•Œë¦¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "error")
        raise ValueError(f"ì•½ ë³µìš© ì•Œë¦¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

async def process_confirm_medicine(text: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì•½ ë³µìš© ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        text (str): ì‚¬ìš©ìì˜ ì…ë ¥ í…ìŠ¤íŠ¸

    Returns:
        str: AI ëª¨ë¸ì˜ ì‘ë‹µ í…ìŠ¤íŠ¸

    Raises:
        ValueError: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš°
    """
    print_log(f"ğŸ’¡ [AIëª¨ë¸] ë°›ì€ í…ìŠ¤íŠ¸: {text}")
    try:
        input_data = {"role": "user", "content": text}
        datasets = [input_data]
        
        # ì•½ ë³µìš© í™•ì¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        response = chat_with_llm(datasets, custom_prompt=MEDICINE_CONFIRMATION_PROMPT)
        print_log(f"ğŸ—£ï¸ ëª¨ë¸ ì‘ë‹µ: {response}")
        return response
    except Exception as e:
        print_log(f"âŒ ì•½ ë³µìš© í™•ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "error")
        raise ValueError(f"ì•½ ë³µìš© í™•ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

async def deliver_to_model(input_text: str) -> dict:
    """
    AI ëª¨ë¸ì— ì…ë ¥ì„ ì „ë‹¬í•˜ê³  ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        input_text (str): ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸

    Returns:
        dict: AI ëª¨ë¸ì˜ ì‘ë‹µ
    """
    print_log(f"ğŸ’¡ [AIëª¨ë¸] ë°›ì€ í…ìŠ¤íŠ¸: {input_text}")
    try:
        # ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        input_data = {"role": "user", "content": input_text}
        datasets = [input_data]
        
        # ëª¨ë¸ì— ì…ë ¥ ì „ë‹¬
        response = chat_with_llm(datasets)
        print_log(f"ğŸ—£ï¸ ëª¨ë¸ ì‘ë‹µ: {response}")
        
        return {"model_output": response}
    except Exception as e:
        print_log(f"âŒ ëª¨ë¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}", "error")
        raise ValueError(f"ëª¨ë¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
